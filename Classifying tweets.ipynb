{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Tweets Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   This project is a small part of a bigger project from my University where the objective was to create an application (mobile and web), which would help people to combat mosquitos that are vectors of _Zika_ virus, reporting their focus (propitious places to reproduce).\n",
    "   To make the platform more precisely, we collected data from Twitter (tweets through _keywords_) that could help us to point suspicous places in the map and classified the labels manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required background knowledge:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Is good to already have knowledge:\n",
    " * Existing predictive models\n",
    " * Feature extraction\n",
    " * Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Know existing predictive models\n",
    "\n",
    "I used some existing and available models on sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction\n",
    "\n",
    "Consists in transforming arbitrary data, such as text or images, into numerical features usable for machine learning. In this project I just used three different Vectorizers to transforming text into usable features for the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation\n",
    "\n",
    "Model Evaluation is a part of the model development process. It helps to find the best model that represents our data and how well the chosen model will work in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My objective is to classify if a tweet is useful or not, to help us to get information about mosquitos and _Zika_ virus.\n",
    "\n",
    "This project consists in build a model to predict a tweet.\n",
    "\n",
    "The labels are:\n",
    "\n",
    " * __Noise__: When tweets are useless in help to get information about mosquitos and _Zika_.\n",
    " \n",
    " * __Receiver__: When tweets can help to get information about mosquitos and _Zika_, but no so well.\n",
    " \n",
    " * __Provider__:When tweets are useful in help to get information about mosquitos and _Zika_.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting to code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Importing libraries_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.dummy import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.svm import *\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.multiclass import *\n",
    "import pandas as pd\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ignore some warnings, about depracated stuff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Reading the dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/macdowell/workspace/classifying-tweets/tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the kind of data and your related types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'text', 'type'], dtype='object')\n",
      "---------------------------------------------\n",
      "id      float64\n",
      "text     object\n",
      "type     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)\n",
    "print(\"---------------------------------------------\")\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset have three columns and as we can see, they are with correct type. We don't need do any kind of cast.\n",
    "\n",
    "For our abroad, we won't use the *id* of the tweets, so let's drop them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm going to split our data set in two sets: *training set* and *test set*.\n",
    "For this, I'll do it automaticly with method __train_test_split()__ from module sklearn.model_selection, where you choose by parameter: test_size and if want to shuffle dataset, then it returns a tuple: __train set, test set, train target set, test target set__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['text'], data['type'], test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obs: Here we also could use __Cross-validation__ from sklearn.model_selection.KFold to split our train/test instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start to perform machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a method to run all algorithms with all Vectorizers once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_models(classifiers, vectorizers, X_train, X_test, y_train, y_test):\n",
    "    string = ''\n",
    "    for classifier in classifiers:\n",
    "        for vectorizer in vectorizers:\n",
    "            string += classifier.__class__.__name__ + ' with ' + vectorizer.__class__.__name__\n",
    "\n",
    "            # train\n",
    "            vectorize_text_train = vectorizer.fit_transform(X_train)\n",
    "            classifier.fit(vectorize_text_train, y_train)\n",
    "            # score\n",
    "            vectorize_text_test = vectorizer.transform(X_test)\n",
    "\n",
    "            predicteds = classifier.predict(vectorize_text_test)\n",
    "            precision, recall, f1, supp = precision_recall_fscore_support(y_test, predicteds,\n",
    "                                                                          average='weighted')\n",
    "            string += '. Precision: ' + str(precision) + '. Recall: ' + str(recall) + ' F1: ' + str(f1) + '\\n'\n",
    "        print(string + '\\n')\n",
    "        string = ''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now calling the method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier with CountVectorizer. Precision: 0.5624601933877599. Recall: 0.641914191419142 F1: 0.5406036589115659\n",
      "AdaBoostClassifier with TfidfVectorizer. Precision: 0.5339725237583999. Recall: 0.6320132013201321 F1: 0.5699842045648011\n",
      "AdaBoostClassifier with HashingVectorizer. Precision: 0.53907862696382. Recall: 0.636963696369637 F1: 0.5593764668638859\n",
      "\n",
      "\n",
      "BaggingClassifier with CountVectorizer. Precision: 0.7592065792469417. Recall: 0.7425742574257426 F1: 0.7175685252875926\n",
      "BaggingClassifier with TfidfVectorizer. Precision: 0.7017153480332634. Recall: 0.7112211221122112 F1: 0.7002951368809374\n",
      "BaggingClassifier with HashingVectorizer. Precision: 0.7398663343519417. Recall: 0.735973597359736 F1: 0.7153822033103645\n",
      "\n",
      "\n",
      "ExtraTreesClassifier with CountVectorizer. Precision: 0.7708943309092993. Recall: 0.7541254125412541 F1: 0.7312140616229972\n",
      "ExtraTreesClassifier with TfidfVectorizer. Precision: 0.7208515639089595. Recall: 0.7178217821782178 F1: 0.6840368561511873\n",
      "ExtraTreesClassifier with HashingVectorizer. Precision: 0.7188958038661009. Recall: 0.7013201320132013 F1: 0.6634216834471887\n",
      "\n",
      "\n",
      "GradientBoostingClassifier with CountVectorizer. Precision: 0.7571338056047919. Recall: 0.7442244224422442 F1: 0.7194351117382956\n",
      "GradientBoostingClassifier with TfidfVectorizer. Precision: 0.7345375083615191. Recall: 0.7376237623762376 F1: 0.7254936944747302\n",
      "GradientBoostingClassifier with HashingVectorizer. Precision: 0.7618884546888985. Recall: 0.7541254125412541 F1: 0.7324379967438627\n",
      "\n",
      "\n",
      "DecisionTreeClassifier with CountVectorizer. Precision: 0.7257489839006197. Recall: 0.731023102310231 F1: 0.7239472058586308\n",
      "DecisionTreeClassifier with TfidfVectorizer. Precision: 0.692296925821411. Recall: 0.698019801980198 F1: 0.6926928197382971\n",
      "DecisionTreeClassifier with HashingVectorizer. Precision: 0.704620651447182. Recall: 0.7128712871287128 F1: 0.7047927851595592\n",
      "\n",
      "\n",
      "DummyClassifier with CountVectorizer. Precision: 0.43676643271324395. Recall: 0.47194719471947194 F1: 0.45260021179935955\n",
      "DummyClassifier with TfidfVectorizer. Precision: 0.450128539234402. Recall: 0.4801980198019802 F1: 0.4624960843158467\n",
      "DummyClassifier with HashingVectorizer. Precision: 0.4378578033933713. Recall: 0.45874587458745875 F1: 0.44675904179344766\n",
      "\n",
      "\n",
      "PassiveAggressiveClassifier with CountVectorizer. Precision: 0.7456301461411649. Recall: 0.7508250825082509 F1: 0.745674942648506\n",
      "PassiveAggressiveClassifier with TfidfVectorizer. Precision: 0.7574595027205909. Recall: 0.7607260726072608 F1: 0.7539151110113095\n",
      "PassiveAggressiveClassifier with HashingVectorizer. Precision: 0.7525242646449709. Recall: 0.7541254125412541 F1: 0.745436858580237\n",
      "\n",
      "\n",
      "RidgeClassifier with CountVectorizer. Precision: 0.7508635193530426. Recall: 0.7524752475247525 F1: 0.7403578708823831\n",
      "RidgeClassifier with TfidfVectorizer. Precision: 0.7805865615724012. Recall: 0.7755775577557755 F1: 0.7649945842173317\n",
      "RidgeClassifier with HashingVectorizer. Precision: 0.7799049672409102. Recall: 0.7557755775577558 F1: 0.7304898640208674\n",
      "\n",
      "\n",
      "RidgeClassifierCV with CountVectorizer. Precision: 0.7569831829763922. Recall: 0.7425742574257426 F1: 0.7184048954830016\n",
      "RidgeClassifierCV with TfidfVectorizer. Precision: 0.7752205496206167. Recall: 0.764026402640264 F1: 0.7471920356375976\n",
      "RidgeClassifierCV with HashingVectorizer. Precision: 0.773123404871145. Recall: 0.7508250825082509 F1: 0.7264662988071177\n",
      "\n",
      "\n",
      "SGDClassifier with CountVectorizer. Precision: 0.7224664754287345. Recall: 0.7227722772277227 F1: 0.7203614497294109\n",
      "SGDClassifier with TfidfVectorizer. Precision: 0.7709886838957954. Recall: 0.7722772277227723 F1: 0.7674747421954966\n",
      "SGDClassifier with HashingVectorizer. Precision: 0.7647981875014728. Recall: 0.7656765676567657 F1: 0.7583988652692049\n",
      "\n",
      "\n",
      "OneVsRestClassifier with CountVectorizer. Precision: 0.7513248085942199. Recall: 0.7524752475247525 F1: 0.7433874270141145\n",
      "OneVsRestClassifier with TfidfVectorizer. Precision: 0.7791484178342143. Recall: 0.7755775577557755 F1: 0.7639174974446724\n",
      "OneVsRestClassifier with HashingVectorizer. Precision: 0.766372354164186. Recall: 0.7425742574257426 F1: 0.715775965092041\n",
      "\n",
      "\n",
      "OneVsRestClassifier with CountVectorizer. Precision: 0.7716626997276231. Recall: 0.764026402640264 F1: 0.7512970995819267\n",
      "OneVsRestClassifier with TfidfVectorizer. Precision: 0.7736418588001085. Recall: 0.7326732673267327 F1: 0.6904061700521771\n",
      "OneVsRestClassifier with HashingVectorizer. Precision: 0.757304553392965. Recall: 0.7178217821782178 F1: 0.6702866723581539\n",
      "\n",
      "\n",
      "KNeighborsClassifier with CountVectorizer. Precision: 0.5943769408367612. Recall: 0.6072607260726073 F1: 0.5943065854702626\n",
      "KNeighborsClassifier with TfidfVectorizer. Precision: 0.7364647195250305. Recall: 0.7376237623762376 F1: 0.7351590548056839\n",
      "KNeighborsClassifier with HashingVectorizer. Precision: 0.6839960953931562. Recall: 0.6897689768976898 F1: 0.6839337734622661\n",
      "\n",
      "\n",
      "BernoulliNB with CountVectorizer. Precision: 0.606308382605045. Recall: 0.6584158415841584 F1: 0.566162386902002\n",
      "BernoulliNB with TfidfVectorizer. Precision: 0.606308382605045. Recall: 0.6584158415841584 F1: 0.566162386902002\n",
      "BernoulliNB with HashingVectorizer. Precision: 0.37885446960537633. Recall: 0.6155115511551155 F1: 0.4690210594093116\n",
      "\n",
      "\n",
      "RandomForestClassifier with CountVectorizer. Precision: 0.7797398502844047. Recall: 0.7508250825082509 F1: 0.7186157335483743\n",
      "RandomForestClassifier with TfidfVectorizer. Precision: 0.7543498853197332. Recall: 0.731023102310231 F1: 0.6930459998013869\n",
      "RandomForestClassifier with HashingVectorizer. Precision: 0.7701520394757921. Recall: 0.7244224422442245 F1: 0.6755993221387744\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "perform_models(\n",
    "    [\n",
    "        AdaBoostClassifier(),\n",
    "        BaggingClassifier(),\n",
    "        ExtraTreesClassifier(),\n",
    "        GradientBoostingClassifier(),\n",
    "        DecisionTreeClassifier(),\n",
    "        DummyClassifier(),\n",
    "        PassiveAggressiveClassifier(),\n",
    "        RidgeClassifier(),\n",
    "        RidgeClassifierCV(),\n",
    "        SGDClassifier(),\n",
    "        OneVsRestClassifier(SVC(kernel='linear')),\n",
    "        OneVsRestClassifier(LogisticRegression()),\n",
    "        KNeighborsClassifier(),\n",
    "        BernoulliNB(),\n",
    "        RandomForestClassifier(n_estimators=100, n_jobs=-1),\n",
    "\n",
    "    ],\n",
    "    [\n",
    "        CountVectorizer(),\n",
    "        TfidfVectorizer(),\n",
    "        HashingVectorizer()\n",
    "    ],\n",
    "    X_train, X_test,\n",
    "    y_train, y_test\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As we can see, each model was performed with three different Vectorizer algorithms and outputed your related metrics scores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
